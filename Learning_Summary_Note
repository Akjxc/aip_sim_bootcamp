[25.05.15 (1 / 2)] Phase 2 - ML Workflow
- https://www.kaggle.com/learn/intro-to-machine-learning
1. 데이터 준비/전처리(결측치 처리 등)
2. 예측 대상(Prediction Target) 선택
  - 관례적으로 y 변수에 저장
  - y = melbourne_data.Price
3. 특징(Features) 선택
  - Feature = 모델에 입력되고, 이후 예측에 사용될 열. 모든 열을 특징으로 사용할 수도 있으나, 더 적게 몇몇 열만 선택하는 게 더 나을 수도 있음. 
  - 관례적으로 X 변수에 저장
  - melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
    X = melbourne_data[melbourne_features]
4. Steps for Modeling
  1) Define(정의) : 어떤 유형의 모델을 사용할 것인가? + 하이퍼파라미터 지정(모델의 구조, 학습 방식, 복잡도 등을 결정)
    - melbourne_model = DecisionTreeRegressor(random_state=1)
    - random_state : 재현 가능성 확보를 위한 무작위성 시드 고정. 무작위로 만들어진 상황을 일관되게 유지해서(실험 환경 통제), 내가 진짜 테스트하고 싶은 조건 하나만 바꿔서 실험할 수 있게 하려는 목적.
    - 이해를 위한 예시 : 기출문제집에서 수학 문제를 무작위로 하나 고른 후, 모델에게 풀도록 함. 틀려서 모델을 수정해서 다시 풀도록 하게 해서 성능 개선 유무 및 변화를 파악해야함. 그러나 모델을 수정한 뒤 또다시 무작위로 문제를 골라서 주면, 모델의 성능 개선 유무 및 변화를 파악하기 어려움. 따라서 같은 문제만 주도록 고정해야함. 
    - ⚠️ 단, 실제 random_state는 문제 자체를 고정하는 것이 아니라, 문제를 어떻게 고를지 결정하는 무작위 흐름의 시작점(seed), 즉 컴퓨터 난수 생성기 알고리즘의 초기값을 고정하는 것. 결과적으로 매번 같은 문제를 선택하게 되므로, 이 비유는 이해를 돕기 위한 직관적 설명이다.
  2) Fit(학습) : 제공된 학습 데이터에서 패턴을 포착하고, 모델을 훈련함. 모델링의 핵심.
    - melbourne_model.fit(X, y)
  3) Predict(예측) : 테스트 데이터에 대해 예측 수행
    - print("Making predictions for the following 5 houses:")
      print(X.head())
      print("The predictions are")
      print(melbourne_model.predict(X.head()))
  4) Evaluate(평가) : 모델이 예측한 결과의 정확도 측정, 평가

[25.05.15 (2 / 2)] Phase 2 - Steps for Modeling 심화 탐구
탐구 1. random_state
  - 비유 vs 실제의 차이
  | 구분     | 수학 문제 비유 (문제까지 고정)    | 실제 random\_state (시드 고정)        |
  | ------ | ------------------ | ------------------------------- |
  | **역할** | 최종 선택된 문제(결과)까지 고정 | 선택 과정을 만드는 무작위 흐름의 시작점만 고정      |
  | **관점** | "이 문제 다시 풀어봐"      | "같은 방식으로 문제집을 다시 뒤져봐"           |
  | **결과** | 항상 같은 문제를 받게 됨     | 항상 같은 문제를 받게 됨 (결국은 같지만 과정이 다름) |
  - 의문점 1) 컴퓨터 난수 생성기 알고리즘의 초기값(시드)을 지정하더라도, 결국 그 알고리즘은 무작위한 난수값을 결과로 뱉는데, 같은 문제를 매번 고를 것이라고 보장할 수 있는가? 카드 게임을 예로 들면, 시드를 정하면 카드 하나가 바로 정해지는 것이 아니라, 선택할 수 있는 카드 패가 고정되어서 그 패에서 무작위의 카드를 고르게 되는 거 아닌가?   
      - 컴퓨터 난수 생성기의 난수는 진짜 random 값이 아님. seed 값마다 나오게 될 난수 시퀀스는 이미 정해져 있음. 
      - 따라서 random_state의 seed 값을 고정시키는 것은, 카드 덱을 섞는 방식과 그 덱에서 뽑아서 나온 카드 패, 그리고 패에서 뽑을 카드의 인덱스를 고정시키는 것과 같다.
      - 컴퓨터 난수 생성기는, 실제로는 난수를 뽑는 게 아니라 시드마다 고정된 난수 시퀀스 목록을 생성. seed를 정해주지 않으면 내부적으로 시스템 시간 등을 활용해 seed가 매번 다르게 초기화되어 사용자 입장에서는 매번 새로운 난수가 나오는 것처럼 보임(난수 생성기 본래의 목적 달성). 그러나 seed 값을 고정하면 결과도 정해져 있어서 실질적인 난수 생성기의 역할을 못함. 즉, seed는 컴퓨터 난수 생성기의 일종의 off 스위치와 같음.    
      - +) 위 작성 내용에서 오개념이 있었음을 인지함. 비유 및 설명을 추후 수정하고, 개념을 제대로 숙지하기.
탐구 2. fit (결정트리 기준)
  - 의문점 1) 내가 임의적인 학습 방법을 지정해주지 않는데, 모델을 어떤 흐름으로 학습시키는 것인가?'
    1) 모델의 패턴 학습 단계
      -fit(X, y)를 호출하면, 모델은 X와 y의 관계를 학습해서 입력 -> 출력 매핑 규칙 생성
    2) 단계별 작동 로직(simplified)
      a. 전체 훈련 데이터를 루트 노드로 시작
      b. 가능한 모든 피처를 대상으로 데이터 분할을 시도 (feature_1 < x, feature_2 == y 등). 각 분할의 불순도(impurity)를 계산
      c. 불순도가 가장 크게 감소하는 피처 + 조건 선택 -> 노드를 분기 
      d. 자식 노드마다 이 과정을 재귀적으로 반복
      e. 설정된 조건(max_depth, min_samples_leaf 등)에 도달하면 리프 노드로 종료
    3) 내부적으로 사용하는 알고리즘: CART (Classification and Regression Tree)
      - Scikit-learn에서는 결정트리 학습 알고리즘이 이미 내장되어 있고 고정(CART) 되어 있음. 따라서 fit()만 호출하면 사전에 정해진 방식대로 학습이 자동으로 진행되는 구조.
    4) 다른 모델들은 fit()할 때 임의적인 학습 방식을 지정할 수 있는가?
      - LogisticRegression, SGDClassifier, KMeans, MLPClassifier(신경망) 등 학습 알고리즘, 학습률, 옵티마이저 등 각각 다양한 설정값 지정 가능. DecisionTreeClassifier, RandomForestClassifier는 학습 알고리즘 고정.

---
[25.05.15 (1 / 2)] Phase 2 - random_state 오개념 교정
오개념 인지 계기 : random_state의 난수 시나리오와 카드 비유를 매핑하던 중, '난수 일부 사용 = 덱에서 뽑아 모은 카드 패 구성' 부분에서 GPT의 카드 패 구성 예시로 '덱의 앞에서 5장 뽑기'를 보고 패를 구성하는 방법(룰)은 임의로, 별도로 설정해주어야 하는건가? 라는 의문점이 생김. 이후 'seed는 덱을 고정해주지만, 뽑는 방식은 내가 정해야한다'는 것을 알게됨. 
1. 컴퓨터 난수 생성기(PRNG) 오개념 - 'seed = 컴퓨터 난수 생성기의 off 스위치' 
  - 오개념 : seed를 고정하면 난수 생성기의 무작위성이 제거되어 무작위성이 사라진다. 
  - 교정 : 
      1) seed 고정 -> PRNG의 초기 상태(무작위 시나리오)를 고정.
      2) 이후 생성되는 난수들은 동일한 수열이지만, 여전히 통계적 무작위성(균일 분포·독립성)을 유지.
      3) seed 고정은 무작위 자체를 '제거'하는 게 아니라, 무작위 과정을 '재현 가능하게 통제'하는 장치.  
      > random_state는 무작위성을 제거하는 것이 아니라, 무작위 과정을 반복 재생하는 녹화/재생 버튼이다.
2. 카드 비유 오개념 - 'seed 값을 고정 =  카드 덱을 섞는 방식, 그 덱에서 뽑아서 나온 카드 패, 그 패에서 뽑을 카드의 인덱스 고정'
  - 오개념: random_state가 덱을 섞은 후 카드 패까지 직접 지정, 즉 고정된 난수 시퀀스에서 자동으로 일부 난수를 사용하고, 자동으로 인덱스 호출까지 해줌.  
  - 교정 :  
      1) 난수 시퀀스 고정(덱 섞는 방식 고정)  
          - seed 고정 → 항상 같은 방식으로 섞는 덱 생성  
      2) 난수 일부 사용(난수 호출 방식 / 카드 패 구성)  
          - 코드가 `rand()`를 호출한 횟수만큼 난수를 꺼내며, 그 호출 횟수가 곧 덱에서 뽑아 모은 카드들
          - 예시: “섞인 덱의 앞에서 5장 뽑기” 등 패를 구성하는 방식은 사용자 코드(외부)에서 지정한 로직에 따름 
      3) 특정 카드 뽑기(인덱스 호출)
          - 패에서 N번째 카드를 꺼내는 것은 일부 사용된 난수들 중의 N번째 값을 사용하는 것과 동일
          - 2)에서와 같이, 몇번째 값을 선택할지는 사용자 코드가 결정. 
+) Q. 나는 모델링할 때 random_state의 시드값만 정했지, 특정 난수 호출 방식이나 특정 인덱스 호출을 결정하는 코드를 작성한 적은 없는데? (의사결정트리 모델 실습 기준)  
      A. 라이브러리(Scikit-learn) 내부에서 난수를 호출하는 횟수와 위치는 이미 정해져 있음. 
          - 예를 들어 DecisionTreeRegressor(random_state=1)를 fit(X, y) 하면,
              1) 루트 노드 분할 시 후보 피처를 뽑거나(불순도 동점 처리),
              2) 자식 노드 재귀 호출 시에도 조건이 중복될 때 무작위로 선택하고…
              3) 그 밖에 내부적으로 무작위성을 이용하는 모든 분기점에서 미리 정해진 순서대로 rand() 를 호출하게 됨.
          - 이 “몇 번 호출”과 “어느 순간 호출”은 내의 코드가 아니라 라이브러리 구현(코드 레벨)에 내장되어 있음.
          - 따라서 '난수 호출 방식'과 '인덱스 호출'은 모델 학습 알고리즘이 제어하며, 사용자는 seed만 제공하면 됨. 즉, 카드 비유 오개념 교정 부분의 '사용자 코드'는 '모델 학습 알고리즘'으로 치환해서 이해해도 무방함. 

[25.05.15 (2 / 2)] Phase 2 - Model Validation
1. Model Validation(모델 검증)
  - 구축한 모델이 실제 상황에서도 잘 작동하는지, 즉 예측 정확도를 평가하는 과정. 
  - In-sample Score : 훈련 데이터를 그대로 모델에 넣고 예측 만들고, 그 예측값을 다시 훈련 데이터의 실제값과 비교. 
      - 모델의 실질적인 가치는 새로운 데이터에 대한 예측과 그 정확도에서 비롯됨. '이미 본 데이터'를 다시 맞추는 것은 무의미. 결국 과대적합(overfitting) 여부 가려낼 수 X 
      - 예시 : '녹색 문이 달린 집은 모두 비쌌다'는 훈련 데이터의 우연한 패턴은 대규모 부동산 시장에서 무의미하다고 가정. 
          - 하지만 모델은 해당 패턴을 인식하고 훈련했으므로, 대규모 부동산 시장 데이터(새로운 데이터)에도 녹색 문이 달린 집의 가격을 항상 높게 예측하는 문제 발생.  
  - 시간 부족으로 추후 다시 정리.
