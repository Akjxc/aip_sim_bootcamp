[25.05.15 (1 / 2)] Phase 2 - ML Workflow
1. 데이터 준비/전처리(결측치 처리 등)
2. 예측 대상(Prediction Target) 선택
  - 관례적으로 y 변수에 저장
  - y = melbourne_data.Price
3. 특징(Features) 선택
  - Feature = 모델에 입력되고, 이후 예측에 사용될 열. 모든 열을 특징으로 사용할 수도 있으나, 더 적게 몇몇 열만 선택하는 게 더 나을 수도 있음. 
  - 관례적으로 X 변수에 저장
  - melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
    X = melbourne_data[melbourne_features]
4. Steps for Modeling
  1) Define(정의) : 어떤 유형의 모델을 사용할 것인가? + 하이퍼파라미터 지정(모델의 구조, 학습 방식, 복잡도 등을 결정)
    - melbourne_model = DecisionTreeRegressor(random_state=1)
    - random_state : 재현 가능성 확보를 위한 무작위성 시드 고정. 무작위로 만들어진 상황을 일관되게 유지해서(실험 환경 통제), 내가 진짜 테스트하고 싶은 조건 하나만 바꿔서 실험할 수 있게 하려는 목적.
    - 이해를 위한 예시 : 기출문제집에서 수학 문제를 무작위로 하나 고른 후, 모델에게 풀도록 함. 틀려서 모델을 수정해서 다시 풀도록 하게 해서 성능 개선 유무 및 변화를 파악해야함. 그러나 모델을 수정한 뒤 또다시 무작위로 문제를 골라서 주면, 모델의 성능 개선 유무 및 변화를 파악하기 어려움. 따라서 같은 문제만 주도록 고정해야함. 
    - ⚠️ 단, 실제 random_state는 문제 자체를 고정하는 것이 아니라, 문제를 어떻게 고를지 결정하는 무작위 흐름의 시작점(seed), 즉 컴퓨터 난수 생성기 알고리즘의 초기값을 고정하는 것. 결과적으로 매번 같은 문제를 선택하게 되므로, 이 비유는 이해를 돕기 위한 직관적 설명이다.
  2) Fit(학습) : 제공된 학습 데이터에서 패턴을 포착하고, 모델을 훈련함. 모델링의 핵심.
    - melbourne_model.fit(X, y)
  3) Predict(예측) : 테스트 데이터에 대해 예측 수행
    - print("Making predictions for the following 5 houses:")
      print(X.head())
      print("The predictions are")
      print(melbourne_model.predict(X.head()))
  4) Evaluate(평가) : 모델이 예측한 결과의 정확도 측정, 평가

[25.05.15 (2 / 2)] Phase 2 - Steps for Modeling 심화 탐구
탐구 1. random_state
  - 비유 vs 실제의 차이
  | 구분     | 수학 문제 비유 (문제까지 고정)    | 실제 random\_state (시드 고정)        |
  | ------ | ------------------ | ------------------------------- |
  | **역할** | 최종 선택된 문제(결과)까지 고정 | 선택 과정을 만드는 무작위 흐름의 시작점만 고정      |
  | **관점** | "이 문제 다시 풀어봐"      | "같은 방식으로 문제집을 다시 뒤져봐"           |
  | **결과** | 항상 같은 문제를 받게 됨     | 항상 같은 문제를 받게 됨 (결국은 같지만 과정이 다름) |
  - 의문점 1) 컴퓨터 난수 생성기 알고리즘의 초기값(시드)을 지정하더라도, 결국 그 알고리즘은 무작위한 난수값을 결과로 뱉는데, 같은 문제를 매번 고를 것이라고 보장할 수 있는가? 카드 게임을 예로 들면, 시드를 정하면 카드 하나가 바로 정해지는 것이 아니라, 선택할 수 있는 카드 패가 고정되어서 그 패에서 무작위의 카드를 고르게 되는 거 아닌가?   
      - 컴퓨터 난수 생성기의 난수는 진짜 random 값이 아님. seed 값마다 나오게 될 난수 시퀀스는 이미 정해져 있음. 
      - 따라서 random_state의 seed 값을 고정시키는 것은, 카드 덱을 섞는 방식과 뽑을 카드의 순서를 고정시키는 것과 같다.
      - 컴퓨터 난수 생성기는, 실제로는 난수를 뽑는 게 아니라 시드마다 고정된 난수 시퀀스 목록을 생성. seed를 정해주지 않으면 내부적으로 시스템 시간 등을 활용해 seed가 매번 다르게 초기화되어 사용자 입장에서는 매번 새로운 난수가 나오는 것처럼 보임(난수 생성기 본래의 목적 달성). 그러나 seed 값을 고정하면 결과도 정해져 있어서 실질적인 난수 생성기의 역할을 못함. 즉, seed는 컴퓨터 난수 생성기의 일종의 off 스위치와 같음.    
      - +) 위 작성 내용에서 오개념이 있었음을 인지함. 비유 및 설명을 추후 수정하고, 개념을 제대로 숙지하기.
탐구 2. fit (결정트리 기준)
  - 의문점 1) 내가 임의적인 학습 방법을 지정해주지 않는데, 모델을 어떤 흐름으로 학습시키는 것인가?'
    1) 모델의 패턴 학습 단계
      -fit(X, y)를 호출하면, 모델은 X와 y의 관계를 학습해서 입력 -> 출력 매핑 규칙 생성
    2) 단계별 작동 로직(simplified)
      a. 전체 훈련 데이터를 루트 노드로 시작
      b. 가능한 모든 피처를 대상으로 데이터 분할을 시도 (feature_1 < x, feature_2 == y 등). 각 분할의 불순도(impurity)를 계산
      c. 불순도가 가장 크게 감소하는 피처 + 조건 선택 -> 노드를 분기 
      d. 자식 노드마다 이 과정을 재귀적으로 반복
      e. 설정된 조건(max_depth, min_samples_leaf 등)에 도달하면 리프 노드로 종료
    3) 내부적으로 사용하는 알고리즘: CART (Classification and Regression Tree)
분할 기준:

분류 문제: 지니 지수(Gini index), 엔트로피(Entropy)

회귀 문제: 평균제곱오차(MSE)

학습 중 내가 학습 알고리즘을 지정하지 않는 이유는?

Scikit-learn에서는 결정트리 학습 알고리즘이 이미 내장되어 있고 고정(CART) 되어 있기 때문이야.

즉, 너는 fit()만 호출하면 사전에 정해진 방식대로 학습이 자동으로 진행되는 구조야.
