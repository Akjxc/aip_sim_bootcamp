# 프로젝트 기반 학습(PBL)으로 AIP 시뮬레이션 핵심 역량 쌓기 (24주 과정)

- aip_sim_v8

**목표**: Palantir AIP(Artificial Intelligence Platform)의 핵심 구조 및 작동 방식(Ontology, Agent, Workflow, LLM, Tool 등)을 이해하고, Kaggle 데이터셋을 활용하여 유사한 기능을 구현하는 프로젝트를 완성함으로써 관련 기술 역량 및 실무 경험 확보.

**예상 학습 시간**: 주당 10~15시간

---

## Phase 0: Palantir AIP 개념 뇌에 심기 (1주)

- **목표**: AIP 구조와 철학 이해 (기술 구현보다는 개념 학습 단계)
- **활동**
    - [build.palantir.com](http://build.palantir.com/), https://www.palantir.com/docs 문서 탐색 및 AIP/Foundry 데모 영상 시청, 블로그/소개 자료 정리
    - LLM (Gemini, ChatGPT 등) 활용하여 AIP 개념 및 구성 요소(Ontology, Agent, Workflow 등)에 대해 질문하고 토론하며 이해 넓히기
        - **[추가/권장 활동 1]** 팔란티어 공식 문서를 NotebookLM 등 RAG 기반 AI 툴에 업로드하여 기술 분석 및 사실 관계 확인 인터페이스로 활용해보기
            - **[참고]** RAG 툴 답변은 제공된 문서 내용에 기반하므로 일반 LLM보다 신뢰도가 높지만, 문서에 없는 내용은 답변할 수 없으며 해석 오류 가능성이 있으므로, 항상 공식 문서 원문을 확인하는 습관을 유지해야 합니다.
        - **[추가/권장 활동 2]** Gemini, ChatGPT 등 일반 생성형 AI와 AIP 개념에 대해 자유롭게 토론하며 '내 관점'으로 해석하고 다른 개념과 연결해보는 연습하기
            - **[참고]** 일반 생성형 AI는 개념 탐색과 비유 생성에 유용하지만, 구체적인 기술적 사실이나 내부 작동 방식에 대한 정보는 부정확할 수 있으므로, 반드시 공식 문서나 RAG 툴을 통해 교차 검증해야 합니다.
- **성과물**: AIP 핵심 개념 및 구성 요소 정리 (문서 또는 마인드맵)
- **완료 기준**:
    - **Checkpoint 0.1**: Phase 0 활동에 명시된 build.palantir.com, [palantir.com/docs](https://palantir.com/docs) 등 핵심 문서 탐색, 데모 영상 시청, 관련 자료 정리를 완료했음을 스스로 확인. (활동 수행 여부 확인)
    - **Checkpoint 0.2**: Phase 0 성과물인 핵심 키워드 5개 요약 성과물을 작성 완료함. (성과물 작성 여부 확인)
    - **Checkpoint 0.3**: Phase 0 성과물인 데모 영상 시청 기반 UI 흐름 노트 성과물을 작성 완료함. (성과물 작성 여부 확인)
    - **Checkpoint 0.4**: 작성된 성과물들 (키워드 요약, UI 흐름 노트)을 통해, AIP의 Ontology, Agent, Workflow 핵심 개념이 무엇이며 이들이 서로 어떻게 연결되고 어떤 기본적인 역할 분담을 하는지에 대한 스스로의 기본적인 이해를 확인할 수 있음. (개념 이해도 확인)

---

## Phase 1: Python & 데이터 기본기 재장전 (1.5주)

- **목표**: Python 문법 및 데이터 조작/분석 라이브러리(Pandas) 기본 사용법 복습 및 실습
- **활동**
    - Python 기본 문법 복습 (변수, 자료형, 제어문, 함수, 클래스 기본 등)
    - Pandas 라이브러리 기본 사용법 학습 및 실습 (DataFrame 생성/수정, 데이터 읽기/쓰기, 기본 집계/정렬/필터링 등)
    - 선택한 Kaggle 데이터셋을 Pandas DataFrame으로 로딩하고 기본 정보(컬럼, 데이터 타입, 결측치 등) 확인 실습
    - **[필수 고려사항] 데이터셋 최종 선정:** 본 커리큘럼에서 사용할 Kaggle 데이터셋을 Phase 1 종료 시점까지 최종적으로 선정하고 고정. 이후 Phase에서는 데이터셋 변경으로 인한 리팩터링을 최소화함. **(타이타닉 데이터셋으로 진행하며, 필요시 Ontology 심화는 별도 데이터 실습 고려)**
- **성과물**: Python 기본 문법 연습 코드, Pandas 기본 조작 연습 코드, 데이터 로딩 및 기본 정보 확인 코드
- **완료 기준**:
    - **Checkpoint 1.1**: Phase 1 활동에 명시된 Kaggle Pandas mini-course 실습 및 감잡기용 임의 테스트 문제 풀이를 모두 완료했음을 스스로 확인. (주요 학습 활동 수행 완료 확인)
    - **Checkpoint 1.2**: 성과물인 "전처리 실습 노트북"을 작성 완료하고, 해당 노트북의 코드가 제공된 데이터를 사용하여 결측치 처리, 데이터 그룹화, 기본적인 인코딩(One-Hot Encoding, Label Encoding 등 기본적인 방법론) 등 명시된 '기본적인 수준'의 데이터 전처리 작업을 오류 없이 수행하며, 결과 데이터프레임이 예상대로 구성됨을 확인. (핵심 기본 전처리 기술 구현 확인)
    - **Checkpoint 1.3**: 성과물인 "EDA 함수 1~2개 정리"를 작성 완료하고, 해당 함수들이 Pandas 데이터프레임을 입력받아 기본적인 데이터 탐색 또는 정제 기능(예: 특정 컬럼의 결측치 비율 계산, 특정 컬럼의 고유값 개수 계산, 간단한 데이터 타입 변환 등)을 수행함을 확인. (기본 데이터 조작 함수 구현 확인)
    - **Checkpoint 1.4**: 위 활동들을 통해 Pandas 라이브러리의 기본적인 데이터 로딩, 선택, 필터링, 조작, 분석 기능 사용법을 익혔음을 스스로 확인. (Pandas 기본기 습득 자가 평가)

---

## Phase 1.5: 데이터 시각화 및 EDA 기본 (0.5주)

- **목표**: 시각화의 쓰임새 체감 및 데이터 특징/품질 기본 파악 능력 습득
- **활동**
    - Kaggle Data Visualization mini course 실습
    - Matplotlib/Seaborn 등 활용하여 데이터의 분포, 관계 등 기본적인 특징 시각화 실습
    - 타이타닉 데이터 등으로 기본적인 질문형 분석 후 시각화 (예: 성별/선실 등급별 생존율)
    - outlier, skew, boxplot, countplot 등 데이터 품질 관련 기본 개념을 시각적으로 파악하는 방법 학습 및 실습
- **성과물**: 시각화 예제 5개 + 한줄 해석, EDA notebook 1개
- **완료 기준**:
    - **Checkpoint 1.5.1**: Phase 1.5 활동에 명시된 Kaggle Data Visualization mini course 실습을 완료했음을 스스로 확인. (주요 학습 활동 수행 완료 확인)
    - **Checkpoint 1.5.2**: 성과물인 "시각화 예제 5개 + 한줄 해석"을 작성 완료하고, 예제들이 Matplotlib/Seaborn을 활용하여 데이터의 분포, 변수 간 관계 등 기본적인 특징을 시각화하고 각 시각화에 대한 핵심적인 해석이 포함됨을 확인. (기본 시각화 구현 및 해석 확인)
    - **Checkpoint 1.5.3**: 성과물인 "EDA notebook"을 작성 완료하고, 해당 노트북에 boxplot, countplot 등 특정 시각화 도구를 사용하여 데이터의 이상치(outlier), 치우침(skew) 등 데이터 품질 관련 기본 개념을 시각적으로 파악하는 시각화 결과와 그 해석이 포함됨을 확인. (데이터 품질 시각화 및 파악 능력 확인 - Phase 1.5의 핵심 활동 반영)

---

## Phase 2: 머신러닝 기본기, 필수 전처리, 파이프라인 구현 & 모델 저장 (3.5주)

- **목표**: ML 모델링 흐름 이해 및 기본적인 파이프라인 코드 구현 능력 습득, 다음 단계 연동 준비
- **활동**
    - [핵심 필수 학습 내용] (Phase 1/1.5에서 다진 기본기 바탕으로 진행)
        1. ML 모델 입력을 위한 필수 전처리 심화 학습 및 실습: 수치형 데이터 스케일링(StandardScaler, MinMaxScaler 등), 범주형 데이터 인코딩(One-Hot Encoding 등) 심화, 간단한 Text Preprocessing 기본(불용어 제거 등), 이상치 처리 기본(제거, 대체 등) 등 Scikit-learn의 Transformer 활용
        2. 기본 ML 모델 학습 및 실습: Scikit-learn을 활용하여 기본적인 분류 모델(Logistic Regression) 및 회귀 모델(Linear Regression) 학습 및 예측 실습
        3. ML 파이프라인 구현 필수 기술 학습 및 실습: Scikit-learn의 `Pipeline` 및 `ColumnTransformer` 활용법 학습 및 실습
            - **[추가 가이드]** 복잡한 전체 파이프라인을 만들기 전에, 2-3개의 간단한 전처리 단계(예: 특정 컬럼 스케일링 + 다른 컬럼 인코딩)만 `ColumnTransformer`와 `Pipeline`으로 묶어보고 데이터 변환 결과를 확인하는 '미니 실습'을 먼저 수행하는 것을 권장합니다.
        4. ML 모델 평가 필수 지식 학습: ML 모델 평가 지표의 종류 및 선택 기준 학습 (분류: Accuracy, Precision, Recall, F1, ROC AUC 등 / 회귀: MSE, RMSE, R2 등)
        5. **ML 모델 평가 지표 계산 방법 학습 및 실습:** Scikit-learn의 `metrics` 모듈 등 라이브러리를 활용하여 실제 모델 예측 결과(`y_pred`)와 실제 값(`y_true`)을 기반으로 평가 지표 값을 코드로 계산하는 구체적인 방법 학습 및 실습. **분류 모델의 경우 평균 정확도 외에 정밀도(Precision), 재현율(Recall), F1-score, 그리고 혼동 행렬(Confusion Matrix) 등 다른 핵심 평가 지표들도 함께 계산하고 해석하는 방법 학습 및 실습을 포함합니다.**
        6. **교차검증(Cross-validation) 개념 학습 및 기본적인 적용 실습:**
            - 모델 성능 평가의 신뢰성을 높이기 위한 교차검증의 개념 학습 (Train/Test Split의 한계 이해 포함).
            - Scikit-learn의 `KFold` 또는 `cross_val_score` 등 기본적인 교차검증 관련 클래스/함수 사용법 학습.
            - 구축한 파이프라인에 대해 Scikit-learn을 활용한 기본적인 K-Fold 교차검증을 데이터셋에 적용하고 결과를 확인하는 실습.
        7. 모델 저장 및 불러오기 필수 기술 학습: `joblib` 또는 `pickle` 라이브러리를 활용하여 학습된 모델 객체를 파일로 저장하고 다시 불러오는 방법 학습 및 실습
        8. ML 모델 평가 루틴 (스크립트 또는 노트북 셀 시퀀스) 작성 및 실행: 구축한 파이프라인의 예측 결과에 대해 핵심 평가 지표들을 계산하고 보고하는 자동화된 루틴 작성 및 실행 연습
    - 위 학습 내용을 바탕으로 데이터 로딩 → 전처리 → 모델 학습 → 예측 → 평가 → 모델 저장으로 이어지는 기본적인 ML 파이프라인 코드 작성 및 실습 (최소 한 가지 모델 유형에 대해 파이프라인 완성)
    - [추가된 활동] 완성된 ML 파이프라인 및 모델 저장/불러오기 기능, 그리고 평가 루틴이 올바르게 작동하는지 확인 (Checkpoint 2.1~2.5 관련 실습)
    - **[권장 활동/참고] 코드 품질 및 표준 관리 :**
        - 일반적인 Python 코딩 스타일 가이드(예: PEP 8 핵심 내용) 학습.
        - 함수, 클래스, 모듈 등에 Docstring 작성하는 방법 학습 및 연습.
        - 본격적으로 코드를 작성하는 Phase 2부터 프로젝트 전반에 걸쳐 학습한 표준을 적용하는 연습 시작.
        - **[추가 가이드]** Phase 2에서 정의한 코드 품질 및 표준 가이드라인 파일(`CODE_STANDARDS.md`)은 이후 Phase들에서 새로운 기술이나 코딩 패턴(예: LangChain Tool 구현, Streamlit 상태 관리 등)을 학습하고 적용하면서 지속적으로 내용을 추가하고 개선해나가는 '살아있는 문서'로 관리해야 함을 인지하고 실천합니다.
        - **[참고] 코드 품질 자동화 도구 활용:** `ruff`(린터) 또는 `black`(포맷터)과 같은 코드 품질 자동화 도구를 탐색하고, `pre-commit`과 같은 툴을 활용하여 코드 커밋 전에 자동으로 코드 스타일을 검사/수정하도록 설정하는 방법을 학습 및 적용해보는 것을 권장합니다. (GitHub Codespaces에서도 사용 가능)
    - **[권장 활동/참고] 프로젝트 종속성 관리:** 프로젝트에 사용되는 라이브러리들의 목록과 버전을 관리하고 재현성을 확보하기 위해 **`requirements.txt` 파일로 기록 및 관리**하는 것이 좋습니다. (실무 관행 참고, GitHub Codespaces 사용 시에도 유용)
- **성과물**:
    - ML 파이프라인 구현 코드 (Notebook 또는 .py 파일)
    - 학습 및 저장된 모델 파일 (`.joblib` 또는 `.pkl`)
    - ML 모델 평가 루틴 코드
    - **[추가된 성과물]** 프로젝트 코드 저장소 내 코드 품질 및 표준 가이드라인 파일 (`CODE_STANDARDS.md` 등)
- **완료 기준**:
    - **Checkpoint 2.1 (심화 전처리 구현)**: Phase 2 활동의 첫 번째 [핵심 필수 학습 내용]인 "ML 모델 입력을 위한 필수 전처리 심화" 관련 기술 (수치형 스케일링, 범주형 인코딩 심화, (선택시)텍스트 전처리 기본, 이상치 처리 기본)을 Scikit-learn Transformer 등을 활용하여 코드로 구현하고, 해당 전처리 코드가 데이터에 올바르게 적용되어 모델 입력에 적합한 형태로 변환됨을 확인.
    - **Checkpoint 2.2 (기본 모델 학습 및 예측 구현)**: 두 번째 [핵심 필수 학습 내용]인 **"기본 ML 모델 학습 및 실습" (로지스틱 회귀, 선형 회귀 - 선택한 모델 유형)**을 위해 Scikit-learn을 사용하여 모델을 학습시키고, 테스트 데이터에 대해 성공적으로 예측을 수행하는 코드를 작성하고 실행 가능함.
    - **Checkpoint 2.3 (ML 파이프라인 구축 구현)**: 세 번째 [핵심 필수 학습 내용]인 **"ML 파이프라인 구현 필수 기술" (Scikit-learn Pipeline & ColumnTransformer 활용법)**을 사용하여 구현된 전처리 코드와 학습된 모델을 성공적으로 연결하고 오류 없이 실행되는 ML 파이프라인 객체를 구축하는 코드를 작성하고 실행 가능함.
    - **Checkpoint 2.4 (ML 평가 지표 계산 구현 및 루틴 작동 확인):** Phase 2 활동에서 작성한 **ML 모델 평가 루틴 (스크립트 또는 노트북 셀 시퀀스)을 실행했을 때**, 구축한 파이프라인의 예측 결과에 대해 명시된 ML 모델 평가 지표들(분류/회귀 해당 지표)이 **오류 없이 정확하게 계산되어 보고됨**을 확인.  **(분류 모델의 경우 평균 정확도 외에 정밀도, 재현율, F1-score, 혼동 행렬 등 다른 핵심 지표 포함)** (테스트/평가 루틴 실행 결과 확인)
    - **Checkpoint 2.5 (교차검증 적용 확인): 구축한 파이프라인에 대해 Scikit-learn을 활용한 기본적인 K-Fold 교차검증을 수행하고 결과를 확인할 수 있음.** (새로운 Checkpoint)
    - **Checkpoint 2.6 (모델 직렬화/역직렬화 구현)**: 다섯 번째 [핵심 필수 학습 내용]인 "모델 저장 및 불러오기 필수 기술"을 사용하여 학습 완료된 파이프라인 객체를(.joblib 또는 .pkl 파일 형태) 성공적으로 저장하고, 저장된 파일에서 해당 객체를 불러와(load) 예측 함수 등을 실행했을 때 오류 없이 원래의 파이프라인과 동일하게 작동함을 확인. (Phase 3 연동 준비)
    - **Checkpoint 2.7 (성과물 작성 완료)**: 위 Checkpoint 2.1 ~ 2.6의 모든 구현 내용이 담긴 "ML 파이프라인 실습 노트북 1-2개 (분류/회귀 각 1개 또는 통합, Pipeline 적용)" 성과물과, 학습 완료된 파이프라인 객체가 담긴 "학습된 모델 파일 (.joblib 또는 .pkl)" 성과물을 모두 작성 완료하고 확보함.

---

[완충 기간 1] (1주)

- 목적: Phase 2에서 학습한 밀도 높은 기술 내용 소화 및 예상치 못한 지연 보충

---

## Phase 3: AIP 핵심 구조 구현 (9주)

### Phase 3a: 데이터 및 온톨로지 계층 구현 (3주)

- **목표**: AIP 시뮬레이션에 필요한 데이터 구조 (유사 Ontology) 구현 및 데이터 접근/쿼리 기능 완성.
- **활동 예시**:
    - Ontology 개념 (객체, 관계) 및 이를 Pandas/JSON으로 표현하는 기술적 방법론 학습 및 실습:
        - Ontology 개념 학습 (객체, 관계, 속성 등)
        - **Pandas/JSON 기반으로 객체와 관계를 표현하는 다양한 간단한 방법(예: 객체 테이블, 관계 테이블 분리 / 객체 내부에 연결된 객체 ID 목록 참조 / 중첩 구조 등)을 탐색하고, 프로젝트 데이터셋의 특성에 가장 적합하며 나중에 쿼리하기 용이한 구조를 선택하여 구현**
    - [핵심 필수 학습 내용]
        - **Ontology 관계 탐색 기반 기술 학습 및 실습 (그래프/재귀 기본 포함):**
            - 간단한 그래프(nodes, edges) 표현 방식 학습 (예: Python dict/list 활용 인접 리스트)
            - 기본적인 그래프 탐색 알고리즘 (BFS/DFS) 개념 및 작동 원리 학습
            - 기본적인 재귀 함수 개념 학습 및 간단한 예제 구현 (예: 팩토리얼, 피보나치 등)
            - 위 개념들을 활용하여 간단한 관계 데이터(예: 사람 관계, 조직 구조)에서 원하는 정보(예: '나'로부터 2단계 떨어진 사람 찾기, 특정 관계를 따라 끝까지 탐색하기)를 탐색하는 연습
        - **온톨로지 데이터 접근 및 쿼리 기능을 수행하는 Python 함수 구현:** 구축한 Ontology 데이터 구조에 대해 특정 객체 조회, 관계 탐색(예: 특정 객체와 n단계 떨어진 다른 객체 찾기, 특정 관계를 따라가기) 등을 수행하는 Python 함수 구현
        - **온톨로지 데이터 접근 및 쿼리 기능을 수행하는 LangChain Tool 정의 및 구현:**
            - LangChain `BaseTool` 인터페이스 구현 방법 학습 (예: `name`, `description`, `_run` 메소드 등)
            - 구현된 온톨로지 쿼리 함수와 LangChain Tool 연결
            - **[참고]** `BaseTool` 인터페이스 학습 및 구현 연습 시, LangChain 공식 문서의 `BaseTool` 예제나 (Phase 3b에서 언급된) Calculator Tool 예제를 참고하는 것이 도움이 됩니다. 간단한 예제부터 시작하며 인터페이스를 익히는 것을 권장합니다.
        - **구현한 온톨로지 쿼리 함수 및 데이터 Tool의 기본 작동 테스트 루틴 (함수 또는 스크립트) 작성 및 실행:** 샘플 입력을 사용하여 함수 및 Tool이 예상된 결과를 올바르게 반환하는지 검증하는 루틴 작성
    - 위 학습 내용을 바탕으로 Phase 1.5에서 선정한 데이터셋을 Ontology 데이터 구조로 변환하거나 모델링하여 구현.
- **성과물 예시**: 온톨로지 데이터 구조 코드, 온톨로지 쿼리 함수들, 이를 활용하는 기본 LangChain Tool 코드 (Agent 없이 독립 실행 가능)
- **완료 기준**:
    - **Checkpoint 3a.1 (개념 학습 및 기본 기술 습득 확인)**: Ontology 개념 (객체, 관계), 이를 Pandas/JSON 등 코드 기반으로 표현하는 기술적 방법론, 그리고 온톨로지 관계 탐색에 필요한 그래프/재귀 기본 개념 및 간단한 구현 방법을 학습하고 익혔음을 스스로 확인. (수정: 필수 활동 반영)
    - **Checkpoint 3a.2 (데이터 구조 구현 확인)**: Phase 3a 목표에 맞춰 AIP 시뮬레이션에 필요한 유사 Ontology 데이터 구조를 Pandas DataFrames 또는 JSON 형태로 정의하고 코드로 구현했으며, 객체와 객체 간의 관계(Link)가 해당 구조 내에 명확히 표현됨을 확인.
    - **Checkpoint 3a.3 (온톨로지 쿼리 함수 작동 확인):** 정의된 유사 Ontology 구조에서 관계 기반 데이터를 조회하는 핵심 함수(예: 특정 객체와 연결된 다른 객체 찾기, 다단계 관계 탐색 등)를 구현하고, **작성한 테스트 루틴을 실행했을 때** 샘플 데이터에 대해 **오류 없이 올바르게 작동**하며 예상된 쿼리 결과를 반환함을 확인. (테스트 루틴 실행 결과 확인)
    - **Checkpoint 3a.4 (데이터 Tool 작동 확인):** 구현된 온톨로지 쿼리 기능을 활용하는 LangChain Tool 코드를 정의하고, **작성한 테스트 루틴을 실행했을 때** 해당 Tool이 LangChain Agent 없이 독립적으로 호출되어 예상대로 작동하며 결과를 올바르게 반환함을 확인. (테스트 루틴 실행 결과 확인)
    - **Checkpoint 3a.5 (성과물 작성 확인)**: Phase 3a의 성과물 예시로 명시된 온톨로지 데이터 구조 코드, 온톨로지 쿼리 함수들 코드, 이를 활용하는 기본 LangChain Tool 코드를 모두 작성 완료하고 확보함.

### Phase 3b: Agent 및 모델 활용 계층 구현 (3주)

- **목표**: LangChain Agent 정의 및 학습된 ML 모델을 활용하는 기능 완성.
- **활동 예시**:
    - [핵심 필수 학습 내용]
        - **LangChain Agent 및 Tool 기본 개념 및 구현 학습:**
            - LangChain Agent 정의 코드 스켈레톤 학습 (라이브러리 사용: `initialize_agent` 함수 등)
            - LangChain `BaseTool` 인터페이스 구현 방법 학습 및 실습:
                - LangChain `BaseTool` 인터페이스 학습 (예: `name`, `description`, `_run` 메소드 등)
                - 구현된 온톨로지 쿼리 함수와 LangChain Tool 연결
                - Phase 2에서 저장한 ML 모델을 LangChain Tool로 감싸는 구현 및 테스트
                - **[추가 가이드]** LangChain Tool 입/출력 데이터 처리 유의: Tool의 `_run` 메소드는 문자열만 반환해야 하므로, 구조화된 데이터는 JSON 문자열 등으로 변환하여 반환하고, 입력 인자도 필요한 경우 Tool 내부에서 적절히 파싱해야 함을 유의.
            - [참고] `BaseTool` 인터페이스 학습 및 구현 연습 시, LangChain 공식 문서의 `BaseTool` 예제나 Calculator Tool 예제를 참고하는 것이 도움이 됩니다. 간단한 예제부터 시작하며 인터페이스를 익히는 것을 권장합니다.
        - **Agent가 Tool을 호출하는 방식 이해 및 실습:**
            - Agent의 내부 작동 방식 (예: ReAct 패턴) 개념 학습
            - **LangChain Tool 설명(`name`, `description`) 작성 연습 (프롬프트 엔지니어링 필요):**
                - **Agent가 Tool을 올바르게 선택하고 사용하도록 유도하기 위해 Tool의 `name`과 `description`을 구체적이고 명확하게 작성하는 연습이 필수.**
                - **특히 `description` 작성 시에는 해당 Tool의 사용 목적, 필요한 입력 형태, 출력 결과 예상 등을 LLM이 잘 이해하도록 설명하는 프롬프트 엔지니어링 기법을 고려해야 함.**
                    - **[참고]** Tool 설명(`description`) 작성에 대한 표준이나 가이드라인이 필요한 경우, `CODE_STANDARDS.md` 파일에 추가적으로 정의하여 관리할 수 있습니다.
            - 프롬프트 구성이 Tool 호출에 미치는 영향 학습 및 간단한 예제 실행
            - Agent가 Phase 3a에서 구현한 데이터 Tool과 Phase 3b에서 구현한 모델 Tool을 성공적으로 사용하는지 테스트 및 디버깅
        - LangChain 디버깅 툴킷 사전 세팅 및 활용 연습 (필수): `langchain.debug` 활성화, `VerboseCallbackHandler` 활용 등 Agent의 내부 작동 과정과 Tool 호출 결과 확인 방법 학습 및 연습. Agent가 예상대로 작동하지 않을 때 디버깅 툴을 활용하여 원인 파악 연습.
        - **구현한 Agent 및 Tool 핵심 작동 테스트 루틴 (스크립트) 작성 및 실행:**  테스트 프롬프트에 대해 Agent가 Tool을 올바르게 호출하고 Tool 실행 결과가 예상대로 나오는지 검증하는 루틴 작성 (Checkpoint 3b.3 관련)
    - 위 학습 내용을 바탕으로 Agent가 데이터 Tool, 모델 Tool을 활용하여 간단한 질의에 응답하는 코드 구현.
- **성과물 예시**: LangChain Agent 코드 (Tool 연결 포함), 모델 활용 LangChain Tool 코드, Agent가 데이터/모델 Tool을 사용하는 테스트 코드/스크립트
- **완료 기준**:
    - Checkpoint 3b.1 (Agent/Tool 기본 구현 확인): LangChain Agent 정의 코드 스켈레톤 작성, BaseTool 인터페이스 구현 방법 학습 및 실습을 완료하고, Phase 2에서 저장한 ML 모델을 LangChain Tool로 감싸는 코드 구현을 완료했으며, 해당 모델 Tool이 Agent 없이 독립적으로 호출되었을 때 예상대로 작동함을 확인.
    - Checkpoint 3b.2 (Agent Tool 연결 및 기본 작동 확인): Agent의 내부 작동 방식 학습을 완료하고, Phase 3a에서 구현한 데이터 Tool과 Phase 3b에서 구현한 모델 Tool을 LangChain Agent에 성공적으로 연결하는 코드를 작성했으며, Agent가 연결된 Tool들을 올바르게 인식함을 확인.
    - Checkpoint 3b.3 (Agent Tool 호출 작동 테스트): Agent가 연결된 데이터 Tool과 모델 Tool을 사용하여 테스트 프롬프트에 대해 예상되는 Tool 호출을 올바르게 수행하고 (Agent verbose 모드 등으로 확인), Tool 실행 결과를 바탕으로 최종 응답을 생성하는 가장 기본적인 Agent 작동 흐름이 코드로 구현 및 입증 가능함.
    - **Checkpoint 3b.3 (Agent Tool 작동 확인):** **작성한 Agent 및 Tool 핵심 작동 테스트 루틴을 실행했을 때**, Agent가 연결된 데이터 Tool과 모델 Tool을 사용하여 테스트 프롬프트에 대해 예상되는 Tool 호출을 올바르게 수행하고 (Agent verbose 모드 등으로 확인), Tool 실행 결과를 바탕으로 최종 응답을 생성하는 기본적인 Agent 작동 흐름이 오류 없이 작동함을 입증 가능함. (테스트 루틴 실행 결과 확인)
    - Checkpoint 3b.4 (디버깅 툴 세팅 및 활용 확인): LangChain 디버깅 툴킷(langchain.debug, VerboseCallbackHandler 등)을 성공적으로 세팅하고, Agent 실행 시 툴 호출 과정 및 응답 생성 과정을 추적하여 디버깅에 활용할 수 있음을 직접 실습하여 확인. (Phase 3b 핵심 난이도 완화 포인트)
    - Checkpoint 3b.5 (성과물 작성 확인): Phase 3b의 성과물 예시로 명시된 LangChain Agent 코드 (Tool 연결 포함), 모델 활용 LangChain Tool 코드, Agent가 데이터/모델 Tool을 사용하는 테스트 코드/스크립트를 모두 작성 완료하고 확보함.

### Phase 3c: UI 계층 구현 및 최소 통합 (3주)

- **목표**: Streamlit UI 구현 및 Agent/Tool과 연결하여 기본적인 입출력 흐름 완성.
- **활동 예시**:
    - [핵심 필수 학습 내용]
        - **Streamlit UI 기본 구현 및 상호작용 기술 학습 및 적용:**
            - Streamlit 앱 기본 구조 및 실행 방법 학습 (라이브러리 사용)
            - 사용자 입력 위젯 (text_input 등), 버튼 위젯 (button) 활용 및 콜백 함수 연결 방법 학습 (라이브러리 사용)
            - 결과 표시 위젯 (write, text 등) 활용 방법 학습 (라이브러리 사용)
        - **Streamlit 애플리케이션 상태 관리 기술 학습 및 적용:**
            - **Streamlit의 실행 모델(Script Rerun) 이해** (개념 학습)
            - **`st.session_state` 활용 방법 및 중요성 학습** (라이브러리 사용 + 개념 이해)
            - **상태 유지가 필요한 간단한 기능 구현 실습** (예: 이전 입력/결과 기억 - Agent 대화 기록 관리에 필요)
            - **[추가 가이드]** AIP 시뮬레이션 앱에서 필요한 상태 관리 패턴(예: Agent와의 대화 기록 리스트 관리, 사용자 입력 값 유지 등)을 중심으로 `st.session_state` 활용 연습을 집중적으로 수행하는 것을 권장합니다. Streamlit 공식 문서를 적극 참고하세요.
            - **[참고]** Streamlit 상태 관리 패턴 구현에 대한 팀 내(또는 개인 프로젝트 내) 일관된 코딩 스타일 표준이 필요한 경우 `CODE_STANDARDS.md`에 기록해두는 것이 좋습니다.
        - **AIP 구성 요소 최소 통합 구현:**
            - Phase 3b에서 구현한 Agent 객체를 Streamlit 앱 내에서 로드하거나 초기화
            - Streamlit UI에서 받은 사용자 입력을 Agent에게 전달
            - Agent의 응답을 받아 UI에 표시
            - 위 단계를 연결하여 '입력 → Agent 호출 → 응답 출력' 최소 통합 흐름 구현 및 작동 테스트 수행 (Phase 3 전체의 최소 완수 목표)
            - **[추가 가이드]** UI와 백엔드(Agent, Tool) 연동 시 발생할 수 있는 흔한 오류 유형(예: 데이터 직렬화/역직렬화 문제, 상태 불일치, 백엔드 타임아웃/오류 전파 등)을 인지하고, Phase 3b에서 익힌 디버깅 툴 및 Streamlit의 상태/로그 확인 기능을 활용하여 컴포넌트 간의 데이터/제어 흐름을 추적하는 디버깅 연습을 병행해야 합니다.
- **성과물 예시**: Streamlit 앱 코드 (기본 입출력 흐름 작동 버전), 전체 구성 요소 연결 코드
- **완료 기준**:
    - Checkpoint 3c.1 (Streamlit 기본 UI 구현 확인): Streamlit 앱 기본 구조를 작성하고, 사용자 입력 위젯, 실행 버튼 위젯, 결과 표시 위젯 등 AIP 시뮬레이션 앱의 기본적인 사용자 인터페이스 필수 요소가 코드 상으로 구현되고 배치되어 있음을 확인.
    - Checkpoint 3c.2 (UI 상호작용 및 상태 관리 구현 확인): Streamlit UI에서 버튼 클릭 등 사용자 상호작용이 예상되는 Python 함수 실행과 올바르게 연결되며, st.session_state를 활용하여 Phase 3c 활동에 명시된 기본적인 앱 상태(예: 대화 기록 누적 등)가 올바르게 유지됨을 코드로 구현 및 입증 가능함.
    - **Checkpoint 3c.3 (최소 통합 흐름 작동 확인):** Phase 3b에서 구현한 Agent 객체를 성공적으로 로드/초기화하고 Streamlit UI와 연결하여, **최소 통합 흐름 작동 테스트를 수행했을 때**, Streamlit UI에서 받은 사용자 입력을 Agent에게 전달하고 Agent의 응답을 받아 UI에 표시하는 가장 기본적인 '입력 → Agent 호출 → 응답 출력' 전체 흐름이 오류 없이 작동함을 확인. (테스트 수행 결과 확인 - Phase 3 전체의 최소 완수 목표)
    - Checkpoint 3c.4 (성과물 작성 확인): Phase 3c의 성과물 예시로 명시된 Streamlit 앱 코드 (기본 입출력 흐름 작동 버전) 및 전체 구성 요소 연결 코드를 모두 작성 완료하고 확보함.

---

[완충 기간 2] (1주)

- 목적: Phase 3에서 학습/구현한 여러 구성 요소 소화 및 통합 관련 예상치 못한 문제 해결 시간 확보

---

## Phase 4: 실무형 AIP 스타일 프로젝트 완성 (5주)

- **목표**: 선택한 Kaggle 데이터 기반, 전체 AIP 워크플로우 통합 시뮬레이션 앱 완성 및 문서화
- **활동**
    - [핵심 필수 학습 내용]
        - Ontology – Agent – Workflow 구성 요소 간의 전반적인 통합 아키텍처 설계 및 구현 완성: Phase 3에서 시작한 연결을 확장하여 각 구성 요소(유사 Ontology 코드, Phase 2 파이프라인/모델 코드, Agent/Tool 코드, Streamlit UI 코드)를 하나의 작동하는 앱으로 통합하는 구조 설계 및 데이터/제어 흐름 구현 완성
        - Streamlit UI와 파이프라인 통합 구체성 심화: Streamlit UI 컴포넌트와 백엔드(Agent/데이터 파이프라인) 간의 상호작용 및 상태 관리 로직 완성 (Phase 3 기본 구현 확장)
        - 프로젝트 구조화 및 컴포넌트 인터페이스 설계 연습:
            - Phase 1~3에서 개발한 각 구성 요소를 재사용 가능하고 관리 용이하도록 논리적인 모듈/파일로 분리 관리하는 방법 학습 및 연습. (예: data_layer.py, ml_pipeline.py, agent.py, ui.py 등 역할별 분리)
            - 각 컴포넌트 간의 데이터 전달 방식 및 함수/클래스 호출 인터페이스를 명확히 정의하고 설계하는 방법 학습 및 연습. (예: 어떤 함수는 어떤 입력을 받고 어떤 출력을 반환하는지 명세화 연습)
        - 시스템 통합 디버깅 원칙 및 기법 학습/실습 (필수):
            - 전체 통합 시스템 구축 및 테스트 과정에서 발생하는 문제를 해결하기 위한 시스템 통합 디버깅의 중요성 인지 및 문제 해결 역량 강화.
            - Phase 3b/3c에서 익힌 개별 컴포넌트 디버깅 스킬과 다음 핵심 원칙 및 기법을 통합하여 활용하는 연습 필수:
                1. 데이터/제어 흐름 이해: 시스템 내에서 데이터와 제어가 어떻게 이동하는지 파악하고 시각화(선택 사항).
                2. 문제 지점 특정 및 격리: 오류 발생 시 어느 컴포넌트 또는 경계면이 문제인지 좁히는 연습.
                3. 개별 구성 요소 테스트 활용: 의심 가는 컴포넌트를 독립적으로 테스트하여 문제 확인 연습.
                4. 체계적인 로깅 활용: 각 컴포넌트의 입출력, 상태, 실행 단계 등을 효과적으로 기록하고 추적하는 연습.
                5. 경계면(Interface) 확인: 컴포넌트 간 데이터 전달 형식/값의 정확성 검증 및 오류 처리 연습.
                6. 점진적 통합 및 테스트: 컴포넌트를 조금씩 통합하며 각 단계별 테스트 계획 및 실행 연습.
                7. 표준 디버거 활용: 문제 위치 파악 후, 해당 코드 상세 분석에 디버거 사용.
    - 선택한 Kaggle 데이터 기반 문제 정의 및 Phase 1~3 내용 총동원:
        - 데이터 전처리 (선택 데이터셋에 맞춰 필요한 전처리 기법 적용)
        - 모델 학습 및 활용 (Phase 2에서 학습한 모델 활용, 필요시 추가 학습/튜닝)
        - Agent Tool 구현 (선택 문제에 맞춰 데이터 조회/모델 호출 Tool 구현)
        - Streamlit UI 구현 (사용자 입력/Agent 응답 표시, 상태 관리)
    - 완성된 프로젝트 앱 테스트 및 기능 설명
- **성과물**:
    - 완성된 프로젝트 앱 (Phase 3 기본 기능 넘어서 확장 및 안정화)
    - 사용법/구조 요약 문서 (구현된 기능 위주 설명)
    - [추가된 성과물] 핵심 기능 테스트 시나리오/가이드 (또는 간단한 테스트 스크립트)
- **완료 기준**:
    - Checkpoint 4.1 (전체 통합 아키텍처 완성 확인): Phase 1~3에서 구현한 모든 핵심 구성 요소들 (유사 Ontology 코드, Phase 2 ML 파이프라인/모델 코드, Phase 3b/3c Agent/Tool/UI 코드)이 하나의 프로젝트 구조 내에서 성공적으로 통합되었으며, 각 구성 요소가 서로 예상대로 데이터를 전달하고 기능을 호출하는 전반적인 통합 아키텍처 구현이 완성됨을 확인. (시스템 통합 완성)
    - Checkpoint 4.2 (프로젝트 핵심 기능 작동 확인): 선택한 Kaggle 데이터 기반 문제 정의에 따라, 완성된 프로젝트 앱이 사용자의 입력에 대해 정의된 핵심 기능(예: 특정 질문에 대한 데이터 기반 응답 생성, 데이터 분석 결과 시각화, 모델 예측 결과 제공 등)을 오류 없이 올바르게 수행함을 확인. (주요 기능 구현 및 작동)
    - Checkpoint 4.3 (앱 안정성 및 기본 사용성 확인): 완성된 프로젝트 앱이 기본적인 사용자 상호작용(입력 변경, 버튼 반복 클릭, 특정 데이터 입력 등)에 대해 예기치 않은 오류나 크래시 없이 안정적으로 작동하며, 명시된 사용법에 따라 기본적인 기능들을 사용하는 데 무리가 없음을 확인. (기본적인 품질 및 사용성)
    - **Checkpoint 4.4 (핵심 기능 테스트/검증 수행 및 산출물 확인):** Phase 4 활동에서 정의하고 수행한 **핵심 기능 테스트 루틴 (시나리오/가이드 또는 스크립트)이 작성 완료되었으며**, **해당 테스트를 수행했을 때** 완성된 앱의 핵심 기능이 올바르게 작동함을 스스로 검증했음을 확인. (테스트 루틴 실행 및 결과 확인)
    - Checkpoint 4.5 (성과물 작성 확인): Phase 4의 성과물로 명시된 완성된 프로젝트 앱 코드 (Phase 3c 기본 기능 넘어서 확장 및 안정화된 버전) 및 사용법/구조 요약 문서를 모두 작성 완료하고 확보함. (최종 성과물 작성 완료)

---

[완충 기간 3] (1주)

- 목적: 계획 초과, 마지막 점검, 마무리 작업 등.

---

## Phase X: 아낌없이 주는 문서 및 면접 준비 (1주)

- **목표**: 프로젝트 경험 정리 및 효과적인 전달 능력 강화
- **활동**
    - 전체 개념/코드 요약 정리 (Notion or GitHub)
    - 면접용 스크립트 작성 (Agent 설계, Ontology 활용 등 프로젝트 경험 중심)
    - [핵심 필수 학습 내용]:
        - 프로젝트 경험을 효과적으로 전달하기 위한 문서 템플릿 및 설명 스크립트 구성 방법 학습: (예: 마크다운 구조, 질문-답변 프레임워크 활용)
        **[추가 가이드] 내용 합성 및 명확성 강조:** 프로젝트 경험을 요약하고 구성할 때, 단순히 수행 목록을 나열하기보다, **프로젝트의 핵심 문제, 접근 방식, 기술적 결정, 주요 성과를 중심으로 내용을 '합성'하고 비기술적인 사람(또는 세부 내용을 모르는 면접관)도 이해할 수 있도록 '명확하게 설명'하는 데 집중해야 함.**
- **성과물**:
    - 마크다운 요약 문서 (프로젝트 구조, 구현 내용, 학습 과정 등 포함)
        - **[추가 가이드]** 프로젝트의 한계점(예: 모델 성능)을 솔직하게 명시하고, 이를 개선하기 위한 구체적인 로드맵(예: 하이퍼파라미터 튜닝, 특징 공학, 다른 모델 시도 등 아이디어)을 함께 기술합니다.
        - **[추가 가이드]** (Ontology 심화 별도 실습을 진행했다면) 메인 프로젝트 외에 진행한 Ontology 심화 별도 실습 내용 및 결과(예: 별도 미니 노트북 링크)를 포함하여 Ontology 역량의 깊이를 추가로 어필합니다.
    - 사용 사례 기반 설명 정리 (면접 스크립트 초안)
- **완료 기준**:
    - Checkpoint X.1 (주요 활동 수행 확인): Phase X 활동에 명시된 전체 개념/코드 요약 정리, 면접용 스크립트 작성 활동, 그리고 [핵심 필수 학습 내용]인 프로젝트 경험을 효과적으로 전달하기 위한 방법 학습을 모두 완료했음을 스스로 확인. (주요 활동 및 학습 수행 완료)
    - Checkpoint X.2 (마크다운 요약 문서 작성 확인): 성과물인 "마크다운 요약 문서 (프로젝트 구조, 구현 내용, 학습 과정 등 포함)"를 작성 완료하고, 해당 문서가 프로젝트의 핵심 내용(구조, 구현 기능, 학습 과정, 사용 라이브러리 등)을 체계적으로 요약하여 담고 있음을 확인. (핵심 문서 작성 및 내용 충실도 확인)
    - Checkpoint X.3 (사용 사례 기반 설명 정리 작성 확인): 성과물인 "사용 사례 기반 설명 정리 (면접 스크립트 초안)"를 작성 완료하고, 해당 내용이 프로젝트 경험(특히 Agent 설계, Ontology 활용 등 핵심 요소)을 바탕으로 면접 등에서 예상될 수 있는 질문에 효과적으로 답변하기 위한 초안으로 구성되어 있음을 확인. (면접 준비 초안 작성 및 내용 충실도 확인)
    - Checkpoint X.4 (문서/스크립트 유용성 자가 평가): 작성된 마크다운 요약 문서와 면접 스크립트 초안이 프로젝트 경험을 효과적으로 전달하고 설명하려는 Phase X의 목표 달성에 기여할 수 있는 수준임을 스스로 평가하고 확인. (최종 산출물 유용성 확인)

---

## 선택적 심화 학습 내용 (핵심 커리큘럼 완료 후 고려)

**[참고]** 아래 목록은 Phase 0부터 Phase 4까지의 **핵심 커리큘럼 목표를 성공적으로 완수한 이후**, **추가적인 학습 및 프로젝트 발전을 위해 선택적으로 고려할 수 있는 내용들**입니다. 이 목록은 이번 핵심 프로젝트의 **범위를 명확히** 하고, 향후 발전 방향을 시각적으로 제시하는 **미래 학습 로드맵**의 역할을 합니다.

| 모듈 | 설명 | 관련 페이즈 |
| --- | --- | --- |
| **Phase 2: 정교함 향상** |  | Phase 2 |
| 하이퍼파라미터 튜닝 적용법 (GridSearchCV 또는 RandomizedSearchCV 활용) | GridSearchCV 또는 RandomizedSearchCV를 활용하여 모델의 하이퍼파라미터를 튜닝하는 방법 학습. | Phase 2 |
| 미니 하이퍼파라미터 튜닝 실습 (선택 사항) | GridSearchCV 등을 사용하여 3-4개 정도의 소규모 파라미터만 설정해 한 번 돌려보는 간단한 튜닝 실습. 튜닝 과정을 체험하고 모델 성능을 소폭 개선할 기회를 제공합니다. (실행 시간이 길지 않도록 데이터 샘플링 또는 파라미터 탐색 공간 축소 고려) | Phase 2 |
| 다양한 ML 모델(랜덤포레스트, SVM 등) 학습 및 비교 |  | Phase 2 |
| 고급 특징 공학(Feature Engineering) 기법 학습 및 적용 | 단순 파생변수 생성 이상 | Phase 2 |
| **Phase 3: 고급** |  | Phase 3 |
| LlamaIndex 적용 (RAG 기반 질의응답) | LangChain 외 다른 LLM 연동 프레임워크 체험 (Phase 3 목표와 직결되진 않음) | Phase 3 |
| Ontology JSON 구조 설계 및 정의 작성 심화 | 단순 Pandas/JSON 구현을 넘어, **JSON 데이터의 구조와 제약 조건을 엄격하게 정의하고 유효성을 검사 및 문서화하기 위한 표준인 JSON 스키마(JSON Schema) 작성법 학습 및 실제 프로젝트 데이터 구조에 적용**. (데이터 모델링의 정교함 및 견고함 향상 목표) | Phase 3 |
| **범용성 강화 메타-스키마** | 객체·링크를 JSON Schema로 선언하고 자동 로더·Generic Tool·동적 프롬프트/UI를 생성하여 데이터셋을 바꿔도 *코드 수정 없이* 전체 AIP 흐름 재사용 | Phase 3 |
| **Phase 4: 프로젝트 완성도 및 사용자 경험 향상** |  | Phase 4 |
| 고급 오류 처리 기법 학습 및 적용 | 기본적인 `try...except`를 넘어서는 **특정 예외 상황 처리, 오류 발생 시 상세 로그 기록, 프로그램의 우아한 실패(Graceful Failure), 사용자에게 오류를 명확하고 친절하게 알리는 방법** 등 앱의 안정성과 견고성을 높이기 위한 고급 기법 학습 및 프로젝트 적용. | Phase 4 |
| UI/UX 개선 | 기본적인 Streamlit UI 구현을 넘어, **앱의 레이아웃 개선, 시각적 디자인 요소 적용(테마, CSS 등), 사용자 입력/출력 과정의 편의성 향상(예: 입력 유효성 검사 피드백, 로딩 인디케이터 등) 등 사용자 경험(User Experience)을 고려한 추가 개선** 기법 학습 및 프로젝트 적용. **AIP UI 흐름 벤치마킹 심화 포함.** | Phase 4 |
| **기타 고급 주제** |  | Phase 4 이후 |
| 고급 워크플로우 오케스트레이션 | 복잡한 작업 흐름 관리, 비동기 처리, 작업 큐 등 실무 수준 워크플로우 관리/조정 기법 학습 및 적용. | Phase 4 이후 |
| 간이 거버넌스 시뮬레이션 | 데이터 접근 제어, 감사 로그, 사용자 권한 등 AIP의 거버넌스 개념을 간이적으로 시뮬레이션하는 기능 구현 탐색. | Phase 4 이후 |

---

## 결론

본 커리큘럼의 최종 프로젝트는 선택한 Kaggle 데이터셋에 대해 AIP 핵심 기능(Ontology 쿼리, ML 활용, Agent 연동, 기본 UI)이 작동하는 **MVP(최소 기능 제품) 수준**을 목표로 합니다. 기능 구현 외에 기본적인 코드 품질, 프로젝트 구조화, 시스템 디버깅 능력 등 학습 과정에서 습득한 실무적 모범 사례를 적용하는 것에 중점을 둡니다. 상용 서비스 수준의 완벽한 견고성이나 고성능은 핵심 요구사항이 아니며, 고급 기능 및 완성도 향상은 선택적 심화 학습 내용을 통해 탐구할 수 있습니다.
